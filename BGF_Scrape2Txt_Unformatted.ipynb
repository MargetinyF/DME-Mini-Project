{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<http.client.HTTPResponse object at 0x0000022F42CBD0B8>\n",
      "[\"['3sun Group' '£10m' 'Feb 2014']|\" \"['Abacus' '£4.15m' 'Aug 2013']|\"\n",
      " \"['Accsys Group' '£12m' 'Mar 2017']|\"\n",
      " \"['Acro' '\\\\xa0£7.8m' 'Nov 2015 – Sep 2017']|\"\n",
      " \"['ACS Clothing' '£25.3m' 'Jan 2014']|\"\n",
      " \"['AdEPT Telecom' '£9m' 'Sep 2016']|\" \"['ADEPT4 plc' '£5m' 'Jun 2016']|\"\n",
      " \"['Adestra' '£5.7m\\\\xa0' 'Jan 2016']|\"\n",
      " \"['AimBrain' '£ 4 m  ' 'Jun 2017']|\"\n",
      " \"['Amazon Filters' 'N/A' 'September 2018']|\"\n",
      " \"['Anstey Horne' '£6.6m' 'Mar 2016']|\"\n",
      " \"['Apex Housing Group' '£6.25m' 'June 2018']|\"\n",
      " \"['APS Group' 'N/A' 'Dec 2017']|\"\n",
      " \"['APSU' '£7m' 'Oct 2014 – Nov 2016' '']|\"\n",
      " \"['Arcinova' '£5m' 'June 2018']|\" \"['Aubin' '£2.3m\\\\xa0' 'Feb 2013']|\"\n",
      " \"['AuditComply' 'N/A' 'Dec 2017']|\" \"['Bar Soba' '£3m' 'Nov 2016']|\"\n",
      " \"['Barburrito' '£12.6 million' 'Mar 2012']|\"\n",
      " \"['Benefex' '£5.5 million' 'Oct 2011']|\"\n",
      " \"['BHR Group' '£3.1m' 'Jun 2014']|\"\n",
      " \"['BigBlu Broadband plc' '£14.5m' 'Apr 2016']|\" \"['' 'N/A' 'Jan 2019']|\"\n",
      " \"['Bob & Berts' '£2m' 'Aug 2017']|\" \"['Braidwater' 'N/A' 'Nov 2015']|\"\n",
      " \"['Brindley Healthcare' 'N/A' 'January 2019']|\"\n",
      " \"['Broadband Satellite Services' '£8.3m' 'Jul 2015']|\"\n",
      " \"['Brownhills Glass' '£2.9m' 'Mar 2015']|\"\n",
      " \"['Bullitt Group' '£11.4m' 'Dec 2012']|\"\n",
      " \"['BVG Group' '£10m' 'Jun 2015']|\" \"['Camino' '£4m' 'Dec 2012']|\"\n",
      " \"['Campion Homes' 'N/A' 'Jul 2016\\\\xa0']|\"\n",
      " \"['Care Sourcer' 'N/A' 'May 2017']|\"\n",
      " \"['Carrs Foods' 'N/A' 'November 2018']|\"\n",
      " \"['Cass Art' '£3.2m' 'Dec 2013']|\"\n",
      " \"['Castleton Technology plc' '£2m' 'Jan 2016']|\"\n",
      " \"['Celaton' '£2.5m' 'Dec 2012']|\" \"['Cennox' '£12m' 'Jun 2012']|\"\n",
      " \"['Chemoxy' '£10m' 'Feb 2015 \\\\xa0– Jun 2017']|\"\n",
      " \"['Chesney’s' '£2m\\\\xa0' 'Dec 2016']|\"\n",
      " \"['CHS Healthcare' '£10m' 'January 2018']|\"\n",
      " \"['Clearway Group' '£10m' 'April 2018' '']|\"\n",
      " \"['Click Travel' 'N/A' 'July 2018']|\"\n",
      " \"['Collision Management Systems' '£1.25m' 'July 2018']|\"\n",
      " \"['Coopland & Son' '£8.5m' 'Dec 2017']|\"\n",
      " \"['Coppergreen' '£11.2m' 'Nov 2016']|\"\n",
      " \"['Cornwall Insight' 'N/A' 'Nov 2017']|\"\n",
      " \"['Crêpeaffaire' '£2m' 'Jan 2018' '']|\"\n",
      " \"['Cussins' '£5m' 'Dec 2014 – Oct 2016 ']|\"\n",
      " \"['Cutting Edge Solutions' 'N/A' 'July 2018']|\"\n",
      " \"['Decision Tech' '£10m' 'Oct 2012 – Mar 2018' '']|\"\n",
      " \"['DevOpsGroup' '£3m' 'April 2018']|\"\n",
      " \"['Dianomi' '£6.3m' 'Feb 2018' '']|\" \"['DICE' 'N/A' 'Jul 2017']|\"\n",
      " \"['Direct Online Services' '£3m' 'Oct 2016']|\"\n",
      " \"['Dolphin Homes' '£3.85m' 'Jun 2017']|\" \"['Dudson' '£3m' 'May 2014']|\"\n",
      " \"['Duncan and Todd' '£9.1m' 'Dec 2013 – Mar 2018' '']|\"\n",
      " \"['Ecovision' '£5.4m' 'Aug 2014']|\"\n",
      " \"['Elements Talent Solutions' '£3.45m\\\\xa0' 'October 2018']|\"\n",
      " \"['Entier' '£6.45m' 'Jul 2017']|\"\n",
      " \"['Environmental Essentials' '£3.2m' 'Dec 2015']|\"\n",
      " \"['' 'N/A' 'February 2019']|\"\n",
      " \"['European Braking Systems' 'N/A' 'Dec 2017']|\"\n",
      " \"['Evo Dental' '£4m' 'June 2018']|\" \"['' '£6m' 'November 2018']|\"\n",
      " \"['Filmore & Union' '£3.5m' 'Sep 2017']|\"\n",
      " \"['Firefly Learning' '£3m' 'Nov 2016']|\"\n",
      " \"['Fleetondemand' '£5m' 'October 2018']|\"\n",
      " \"['Flowline' '£5.1m' 'Jun 2014\\\\xa0']|\"\n",
      " \"['Fluidic Analytics' '£ 2 4 m' 'November 2018']|\"\n",
      " \"['Four Communications' '£10m' 'Jul 2015']|\"\n",
      " \"['Frontrow' '£20m' 'Jan 2017']|\"\n",
      " \"['Furniture Village' '£12m' 'Aug 2014']|\"\n",
      " \"['Gaist' '£2.7m' 'May 2018']|\"\n",
      " \"['Garrison Technology' 'N/A' 'March 2017']|\"\n",
      " \"['GCI' '£10m' 'Feb 2012']|\" \"['genedrive plc' '£3.5m' 'December 2018']|\"\n",
      " \"['Giggling Squid' '£6.4m' 'Nov 2015 \\\\xa0']|\"\n",
      " \"['Gousto' '£ 2 8 .' 'Dec 2015']|\" \"['Grace Cole' '£10m' 'Jan 2016']|\"\n",
      " \"['Gymbox' '£25m' 'Jul 2014']|\" \"['HeleCloud' '£2m' 'October 2018']|\"\n",
      " \"['High Access Maintenance' '£3.2m' 'Jul 2016']|\"\n",
      " \"['Hobs Group' '£11.1m\\\\xa0' 'Dec 2014']|\" \"['Hoop' 'N/A' 'Dec 2016']|\"\n",
      " \"['Horbury Group' '£4.5m' 'Jun 2014']|\"\n",
      " \"['Hydrock' 'N/A' 'September 2018']|\"\n",
      " \"['Independent Forgings and Alloys' '£8.5m' 'March 2018']|\"\n",
      " \"['Inoapps' '£14.5m' 'Sep 2013']|\"\n",
      " \"['Intrapharm' '£2m' 'Aug 2014 – Nov 2015']|\"\n",
      " \"['Invenio Business Solutions' '£11.6m' 'March 2019']|\"\n",
      " \"['J&B Recycling' '£7.5m' 'Jul 2014']|\"\n",
      " \"['Johnsons Aggregates' '£5m' 'Oct 2016']|\"\n",
      " \"['Jumpstart' '£3.4m' 'Feb 2014 – Jan 2019']|\"\n",
      " \"['Keenan Recycling' '£2.2m' 'Sep 2015']|\"\n",
      " \"['Kids Planet' '£16.5m' 'Aug 2016\\\\xa0']|\"\n",
      " \"['Lantum' 'N/A' 'Jul 2016']|\" \"['LoopMe' 'N/A' 'October 2018']|\"\n",
      " \"['M Squared Lasers' '£6.7m' 'Apr 2012']|\"\n",
      " \"['M-Flow' '£2.4m' 'Sept 2015\\\\xa0']|\"\n",
      " \"['Magma Global' '£11.8m' 'Dec 2012']|\"\n",
      " \"['Marvel' '£ 4 m  ' 'Aug 2016']|\" \"['Mastered' 'N/A' 'May 2017']|\"\n",
      " \"['McMillan Williams' '£7.7m' 'Feb 2015\\\\xa0']|\"\n",
      " \"['Medicina' '£6m' 'Dec 2013']|\"\n",
      " \"['Medigold Health' '£9.5m' 'Nov 2017']|\" \"['MET' '£8.7m' 'Jun 2017']|\"\n",
      " \"['Milk VFX' '£2m' 'Mar 2015']|\" \"['Miss Group' '£6.4m' 'August 2018']|\"\n",
      " \"['Mission Mars' '£10m' 'July 2018']|\"\n",
      " \"['Molecular Products' '£4m' 'Sep 2014 – Jan 2017']|\"\n",
      " \"['Molson' '£ 6 . 3' 'August 2018']|\"\n",
      " \"['Mono Consultants' '£7.5m' 'Feb 2014']|\"\n",
      " \"['Monodraught' '£2.65m' 'October 2017']|\"\n",
      " \"['MorphCostumes' '£4.2m' 'Jun 2012']|\"\n",
      " \"['MPK Garages' '£7m' 'Mar 2016']|\" \"['' '£10m' 'Dec 2017']|\"\n",
      " \"['MyLife Digital' '£2m' 'Aug 2016 \\\\xa0']|\"\n",
      " \"['Netcall plc' '£7m' 'Aug 2017\\\\xa0']|\"\n",
      " \"['NewVoiceMedia' 'N/A' 'Jan 2016']|\"\n",
      " \"['Nonwovenn' '£9m' 'Apr 2016\\\\xa0']|\"\n",
      " \"['Northern Escalator Installations' '£6.4m' 'January 2018']|\"\n",
      " \"['NSS Group' '£5.5m' 'May 2018']|\" \"['NWC' '£4.5m' '\\\\xa0Oct 2014']|\"\n",
      " \"['Ocee International' '£10m' 'Jul 2016']|\"\n",
      " \"['Olive Communications' '£10m' 'Jan 2016']|\"\n",
      " \"['Oliver Sweeney' '£3.85m' 'December 2014']|\"\n",
      " \"['One Media iP Group Plc' '£6m' 'September 2018']|\"\n",
      " \"['Open Cosmos' 'N/A' 'Dec 2017']|\" \"['' 'N/A' 'March 2019']|\"\n",
      " \"['Paddle' 'N/A' 'Sep 2016']|\" \"['Paintbox' '£8m' 'Feb 2016']|\"\n",
      " \"['Palmer Hargreaves' '£4m' 'Dec 2013']|\"\n",
      " \"['Parklands Group' '£5m' 'December 2018']|\"\n",
      " \"['Petrotechnics' '£7.5m' 'May 2013']|\"\n",
      " \"['Pharmacy2U' '£17m' 'Jul 2016\\\\xa0']|\" \"['' '£3.5m' 'February 2019']|\"\n",
      " \"['Plantforce' '£4.7m' 'July 2018']|\"\n",
      " \"['Plastique' '£5m' 'Jul 2014 – Feb 2016']|\"\n",
      " \"['PPS Equipment' '£4.9m' 'Jul 2015']|\"\n",
      " \"['Prezola' '£3m' 'May 2017\\\\xa0']|\" \"['Primrose' '£4m' 'May 2012']|\"\n",
      " \"['Prodrive Composites' '£7.2m\\\\xa0' 'Jul 2015\\\\xa0']|\"\n",
      " \"['PTS Consulting' '£8.7m' 'Oct 2013']|\"\n",
      " \"['Pureprint' '£5.3m' 'Dec 2014']|\"\n",
      " \"['Purity Brewing Co' '£7.5m' 'August 2018']|\"\n",
      " \"['ReBOUND Returns' 'N/A' 'September 2018']|\"\n",
      " \"['Recordsure' '£7.7m' 'Mar 2014']|\"\n",
      " \"['Red Industries' '£ 3 9 m' 'Jan 2019']|\"\n",
      " \"['Reflex Vans' '£7.9m' 'Jun 2015']|\"\n",
      " \"['Renal Services' '£3.1m\\\\xa0' 'Nov 2014']|\"\n",
      " \"['Renegade Spirits Ireland' '£5m' 'Apr 2017']|\"\n",
      " \"['Rethink Group' '£3.9m' 'Apr 2015']|\" \"['Revital' 'N/A' 'Dec 2017']|\"\n",
      " \"['RiverRidge' '£14.5m' 'Sep 2016']|\"\n",
      " \"['RMS International' '£10m' 'Feb 2016']|\"\n",
      " \"['Roc Technologies' '£10m' 'Oct\\\\xa02017']|\"\n",
      " \"['ROLI' 'N/A' 'May 2016']|\" \"['ROVOP' '£22.7m' 'Apr 2015']|\"\n",
      " \"['RSK Group' '£15m' 'Dec 2016']|\" \"['Ruroc' '£3m' 'May 2018']|\"\n",
      " \"['Rutland Cycling' '£4.3m' 'Mar 2014']|\"\n",
      " \"['RVL Group' '£8.7m' 'Nov 2014']|\" \"['SaleCycle' '£11.5m' 'June 2018']|\"\n",
      " \"['SDL Group' '£19.3m' '\\\\xa0Feb 2015\\\\xa0']|\"\n",
      " \"['Seasalt' '£11.5m' 'September 2018']|\"\n",
      " \"['Semafone' '£4m' 'Oct 2014\\\\xa0']|\"\n",
      " \"['Sentric Music' '£3m' 'Mar 2017 \\\\xa0']|\"\n",
      " \"['Sertec' '£15m' 'Feb 2016']|\"\n",
      " \"['Setfords Solicitors' '£3.8m\\\\xa0' 'Dec 2016']|\"\n",
      " \"['Simworx' '£6.1m\\\\xa0' 'Jul 2015']|\" \"['SLG' '£10m' 'Mar 2015']|\"\n",
      " \"['Sofology' '£10m' 'May 2016' '']|\"\n",
      " \"['Solid Solutions' '£8m' 'Mar 2016']|\"\n",
      " \"['Sophia Webster' '£6.8m' 'Nov 2016']|\" \"['SPEX' '£5m' 'Mar 2014']|\"\n",
      " \"['Spoke' 'N/A' 'December 2018']|\"\n",
      " \"['Springfield Healthcare Group' '£26m' 'Jun 2012']|\"\n",
      " \"['Statesman Travel Group' '£4.2 million' 'Oct 2011 – May 2017']|\"\n",
      " \"['STATS Group' '£12.2m' 'Mar 2012']|\"\n",
      " \"['Stevenswood' '£3.5m' 'Feb 2015 – Nov 2016 \\\\xa0']|\"\n",
      " \"['Streetbees' 'N/A' 'Mar 2017']|\"\n",
      " \"['Styles & Wood' '£3.3m' 'Jun 2015 – Dec 2017' '']|\"\n",
      " \"['Tapdaq' 'N/A' 'Jan 2016']|\"\n",
      " \"['Task Fronterra Group' '£3.8m' 'Apr 2014']|\"\n",
      " \"['Tax Systems plc' '£10m' 'Jul 2016']|\"\n",
      " \"['TCC Group' '£14m\\\\xa0' 'Mar 2014']|\"\n",
      " \"['TCL Group' '£15.1m' 'May 2014']|\"\n",
      " \"['TD4 – Boost Juice Bars and The Shake Lab' '£4.9m' 'Dec 2012']|\"\n",
      " \"['Thames Technology' '£3.1m' 'Dec 2013']|\"\n",
      " \"['The Coaching Inn Group' '£14.5m' 'Mar 2015']|\"\n",
      " \"['The Exchange Lab' '£5m\\\\xa0' 'Nov 2013 – Dec 2015']|\"\n",
      " \"['The Good Care Group' '£2.5m' 'Jul 2016']|\"\n",
      " '[\\'The Plum Guide\\' \"£ 6 m \\'\" \\'Nov 2017\\']|'\n",
      " \"['TickX' '£ 3 m  ' 'Dec 2017']|\" \"['TIG' '£6m' 'January 2018']|\"\n",
      " \"['Total Recycling Services' '£6.7m' 'Aug 2015']|\"\n",
      " \"['toucanBox' '£2.6m' 'May 2016']|\"\n",
      " \"['Triptease' '£3.4m' 'Apr 2017\\\\xa0']|\" \"['Trouva' 'N/A' 'Nov 2017']|\"\n",
      " \"['Trunki' '£6.3m' 'Apr 2013']|\" \"['Uform' 'N/A' 'January 2019']|\"\n",
      " \"['UKCloud' '£18.4m' '\\\\xa0May 2014']|\"\n",
      " \"['Ultra Finishing' '£8m\\\\xa0' 'Jan 2017']|\"\n",
      " \"['Unique Digital' 'N/A' 'December 2018']|\"\n",
      " \"['Unruly' '£4m' 'Dec 2011 – Sep 2015']|\"\n",
      " \"['Victoria plc' '£14.5m' 'Sep 2014']|\" \"['Virtual1' '£10m' 'Dec 2016']|\"\n",
      " \"['Visualisation One' 'N/A' 'June 2018']|\"\n",
      " \"['VTL Group' '£10.5m' 'Sep 2013']|\" \"['Vysiion' '£4m' 'Mar 2015\\\\xa0']|\"\n",
      " \"['Wales Environmental' '£2m' 'Aug 2016\\\\xa0']|\"\n",
      " \"['Walker Precision Engineering' '£4m' 'December 2017']|\"\n",
      " \"['Wear Inns' '£8m' 'May 2012']|\" \"['Wholi' 'N/A' 'Feb 2016']|\"\n",
      " \"['Woodall Nicholson' '£10m' 'Dec 2016']|\"\n",
      " \"['Workshare' '£8.45m' 'Sep 2012']|\"\n",
      " \"['Xercise4less' '£21.7m' 'Aug 2013']|\"\n",
      " \"['York Mailing' '£10m' 'Jul 2013']|\"\n",
      " \"['Zone' '£6m' 'Jan 2015\\\\xa0 – Oct 2017']|\"]\n"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import urllib3\n",
    "from urllib.request import urlopen\n",
    "import regex\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "#this is a basic scrapper which uses BS3 and BS4 to scrape and filter data\n",
    "\n",
    "def line_scrape (lookup, data, skip): #take a lookup tag, datafile, and no of lines to skip\n",
    "    arr1 = np.array([])\n",
    "    counter = 0\n",
    "    for line in data.splitlines():\n",
    "        if lookup not in line: #check if tag present, if not, skip line\n",
    "            counter +=1\n",
    "        else:\n",
    "            counter = counter + skip #if yes, skip n lines\n",
    "            entry = ((data.splitlines()[counter]))\n",
    "            arr1 = np.append(arr1,entry) #aggregate data\n",
    "            arr1 = arr1.reshape((-1, 1)) #turn into column\n",
    "    return arr1\n",
    "            \n",
    "            \n",
    "\n",
    "def scrape_row (link): \n",
    "    link = urlopen(link)#take a link of all htmls\n",
    "    soup = BeautifulSoup(link, \"lxml\") #set decoding system\n",
    "    entry = np.array([]) #create empty array for storing data\n",
    "    arr_final = np.array([])\n",
    "    print (link)\n",
    "    datasize = 0 #tell me how many links you succesfully got the data for\n",
    "    for link in soup.findAll('a', attrs={'href': regex.compile(\"^https://www.bgf.co.uk/our-portfolio/\")}): #for every link in list of all htmls\n",
    "        link_final = (link.get('href'))\n",
    "        new_page=urlopen(link_final)\n",
    "        new_soup = BeautifulSoup(new_page, \"lxml\") #decode the page itself\n",
    "        data1 = new_soup.find(\"body\").get_text() #isolate text\n",
    "        entry1 = line_scrape ('Shape', data1, 9)\n",
    "        entry1 = entry1.astype(str)\n",
    "        if entry1.size ==0:\n",
    "            print (datasize)\n",
    "            entry1 = 'N/A'\n",
    "            \n",
    "        entry2 = line_scrape ('Total BGF investment', data1, 1)\n",
    "        if len (entry2)==(0):\n",
    "            newline =  np.array([])\n",
    "            entry2 = line_scrape ('£', data1, 0)\n",
    "            line = np.array2string(entry2)\n",
    "            iden = line_scrape ('Shape', data1, 9)\n",
    "            position = line.find('£')\n",
    "            if position != -1:\n",
    "                inventive_arr = np.array([])\n",
    "                for i in range (4):\n",
    "                    position_new = (position + i)\n",
    "                    z = line[position_new]\n",
    "                    inventive_arr = np.append(inventive_arr, z)\n",
    "                entry2 = inventive_arr.astype(str)\n",
    "                entry2=' '.join(entry2)\n",
    "            else:\n",
    "                entry2 = 'N/A'     \n",
    "            \n",
    "        entry3 = line_scrape ('Invested since', data1, 1)\n",
    "        if len (entry3)==(0):\n",
    "            entry3 = line_scrape ('Investment between', data1, 1)\n",
    "            if len (entry3)==(0):\n",
    "                entry3 = line_scrape ('Investment', data1, 1) \n",
    "                if len (entry3)==(0):\n",
    "                    entry3 = line_scrape ('Invested', data1, 1) \n",
    "                    if len (entry3)==0:\n",
    "                        print ('no investment')\n",
    "                        iden = line_scrape ('Shape', data1, 9)\n",
    "                        entry3 = 'N/A'\n",
    "                        print (iden)\n",
    "                    \n",
    "                    \n",
    "        entry = np.append(entry,entry1)\n",
    "        entry = np.append(entry,entry2)\n",
    "        entry = np.append(entry,entry3)\n",
    "        entry = np.array2string(entry) #concatenate all entries and unify type of array into string\n",
    "        entry = (entry + '|') #append with delimiter\n",
    "        \n",
    "        arr_final= np.append(arr_final,entry) #make a string array\n",
    "        entry = np.array([])\n",
    "        datasize = (datasize+1)\n",
    "    return arr_final\n",
    "\n",
    " \n",
    "x = scrape_row (\"https://www.bgf.co.uk/full-portfolio-archive/\")\n",
    "print (x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt(fname='meow.txt',fmt='%s', X=x, delimiter='|')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 2
}
